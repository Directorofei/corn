# from langchain_core.messages import HumanMessage
# from langchain_openai import ChatOpenAI
# from config import OPENAI_API_KEY, OPENAI_BASE_URL, MODEL_NAME

# # åˆå§‹åŒ–é€šç”¨ LLM
# llm = ChatOpenAI(
#     api_key=OPENAI_API_KEY,
#     base_url=OPENAI_BASE_URL,
#     model=MODEL_NAME,
#     temperature=0.3
# )

# def pest_detection_agent(state):
#     # æ¨¡æ‹Ÿå›¾åƒè¯†åˆ«ç»“æœ
#     result = "å‘ç°ç‰ç±³å¶ç‰‡æœ‰çº¢èœ˜è››å’Œå¶æ–‘ç—…ç—‡çŠ¶ã€‚"
#     print("[å›¾åƒè¯†åˆ« Agent è¾“å‡º]", result)
#     state["image_description"] = result
#     state["detection_result"] = result
#     return state

# def qa_agent(state):
#     prompt = f"""
#         å›¾åƒæè¿°ï¼š{state['image_description']}
#         é—®é¢˜ï¼š{state['question']}
#         è¯·ç»“åˆå›¾åƒæè¿°å›ç­”é—®é¢˜ï¼š
#         """
#     response = llm.invoke([HumanMessage(content=prompt)])
#     print("[é—®ç­” Agent è¾“å‡º]", response.content)
#     state["answer"] = response.content
#     return state

# def decision_agent(state):
#     prompt = f"""
#         åŸºäºä»¥ä¸‹å›¾åƒè¯†åˆ«ç»“æœå’Œå›ç­”å†…å®¹ï¼Œè¯·ç”Ÿæˆå†œè¯å»ºè®®ï¼š
#         å›¾åƒè¯†åˆ«ç»“æœï¼š{state['detection_result']}
#         é—®é¢˜å›ç­”ï¼š{state['answer']}
#         è¾“å‡ºæ ¼å¼ï¼šå»ºè®®å†…å®¹ + å†œè¯æ¨è
#         """
#     response = llm.invoke([HumanMessage(content=prompt)])
#     print("[å†³ç­– Agent è¾“å‡º]", response.content)
#     state["decision"] = response.content
#     return state


from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
from config import OPENAI_API_KEY, OPENAI_BASE_URL, MODEL_NAME

# åˆå§‹åŒ–é€šç”¨ LLM
llm = ChatOpenAI(
    api_key=OPENAI_API_KEY,
    base_url=OPENAI_BASE_URL,
    model=MODEL_NAME,
    temperature=0.3
)

# å›¾åƒè¯†åˆ«æ™ºèƒ½ä½“
def pest_detection_agent(state):
    # æ¨¡æ‹Ÿå›¾åƒè¯†åˆ«ï¼ˆå¯æ›¿æ¢ä¸ºçœŸå®æ¨¡å‹ï¼‰
    result = "å‘ç°ç‰ç±³å¶ç‰‡æœ‰çº¢èœ˜è››å’Œå¶æ–‘ç—…ç—‡çŠ¶ã€‚"
    print("ğŸ”¬ [å›¾åƒè¯†åˆ« Agent è¾“å‡º]", result)

    state["image_description"] = result
    state["detection_result"] = result
    return state

# é—®ç­”æ™ºèƒ½ä½“
def qa_agent(state):
    image_desc = state.get("image_description", "æ— å›¾åƒä¿¡æ¯")
    question = state.get("question", "")

    prompt = f"""
å›¾åƒæè¿°ï¼š{image_desc}
ç”¨æˆ·æé—®ï¼š{question}

è¯·ç»“åˆå›¾åƒå’Œé—®é¢˜ï¼Œæä¾›ä¸“ä¸šã€ç®€æ´ã€å¯æ‰§è¡Œçš„ç—…è™«å®³ç®¡ç†å»ºè®®ã€‚
"""
    response = llm.invoke([HumanMessage(content=prompt)])
    print("ğŸ§  [é—®ç­” Agent è¾“å‡º]", response.content)

    state["answer"] = response.content
    return state

# å†œè¯å†³ç­–æ™ºèƒ½ä½“
def decision_agent(state):
    detection = state.get("detection_result", "æ— è¯†åˆ«ä¿¡æ¯")
    answer = state.get("answer", "æ— é—®ç­”å†…å®¹")

    prompt = f"""
ä½ æ˜¯ä¸€åå†œä¸šæ¤ä¿ä¸“å®¶ã€‚

æ ¹æ®ä»¥ä¸‹è¯Šæ–­ä¿¡æ¯å’Œé—®ç­”å†…å®¹ï¼Œè¯·åˆ¶å®šé’ˆå¯¹æ€§çš„å†œè¯ä½¿ç”¨å»ºè®®ï¼š

å›¾åƒè¯†åˆ«ç»“æœï¼š{detection}
ä¸“å®¶å›ç­”å†…å®¹ï¼š{answer}

è¯·æ˜ç¡®åˆ—å‡ºï¼š
1. é˜²æ²»å¯¹è±¡
2. è¯å‰‚åç§°ï¼ˆé€šç”¨å+å‰‚å‹ï¼‰
3. ä½¿ç”¨æµ“åº¦æˆ–ç”¨é‡ï¼ˆäº©/æ¬¡ï¼‰
4. å®‰å…¨é—´éš”æœŸ
"""
    response = llm.invoke([HumanMessage(content=prompt)])
    print("ğŸ’Š [å†³ç­– Agent è¾“å‡º]", response.content)

    state["decision"] = response.content
    return state
