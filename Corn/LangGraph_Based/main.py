import time
import sys
import threading
from Graph import build_graph, AgentState
from fastapi import FastAPI, Query
import uvicorn
import uuid
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Optional

app = FastAPI()

# å…¨å±€åˆå§‹åŒ–graphï¼Œé¿å…é‡å¤æ„å»º
graph_app = build_graph()

# Pydanticæ¨¡å‹å®šä¹‰
class AskRequest(BaseModel):
    question: Optional[str] = None
    image_path: Optional[str] = None

class AskResponse(BaseModel):
    answer: Optional[str] = None
    detection_result: Optional[str] = None
    decision: Optional[str] = None

# æµå¼è¾“å‡ºå‡½æ•°
def stream_print(text, prefix="", delay=0.03):
    """
    æ¨¡æ‹Ÿæ‰“å­—æœºæ•ˆæœï¼Œä¸€ä¸ªå­—ä¸€ä¸ªå­—åœ°è¾“å‡º
    """
    print(f"{prefix}", end="", flush=True)
    for char in text:
        print(char, end="", flush=True)
        time.sleep(delay)
    print()  # æ¢è¡Œ

def stream_agent_output(agent_name, output_text, delay=0.02, use_streaming=False):
    """
    æµå¼è¾“å‡ºæ™ºèƒ½ä½“ç»“æœ
    """
    if not output_text:
        return
    
    print(f"\nğŸ¤– {agent_name} æ­£åœ¨æ€è€ƒ...", end="", flush=True)
    time.sleep(0.5)  # æ¨¡æ‹Ÿæ€è€ƒæ—¶é—´
    print("\r", end="", flush=True)  # æ¸…é™¤"æ­£åœ¨æ€è€ƒ"
    
    if use_streaming:
        # æµå¼è¾“å‡ºï¼ˆå¯èƒ½æœ‰é‡å¤é£é™©ï¼‰
        lines = output_text.split('\n')
        for i, line in enumerate(lines):
            if line.strip():  # è·³è¿‡ç©ºè¡Œ
                if i == 0:
                    stream_print(line, f"ğŸ¤– {agent_name}: ", delay)
                else:
                    stream_print(line, "    ", delay)
            else:
                print()  # ç©ºè¡Œç›´æ¥æ¢è¡Œ
    else:
        # ç›´æ¥è¾“å‡ºå®Œæ•´æ–‡æœ¬ï¼ˆæ¨èï¼Œé¿å…é‡å¤ï¼‰
        print(f"ğŸ¤– {agent_name}: {output_text}")

# APIè·¯ç”±
@app.post("/api/ask", response_model=AskResponse)
async def ask(data: AskRequest):
    state: AgentState = {
        "question": data.question,
        "image_path": data.image_path,
        "image_description": None,
        "detection_result": None,
        "answer": None,
        "need_medication": None,
        "decision": None
    }
    result = graph_app.invoke(state)
    return AskResponse(
        answer=result.get("answer"),
        detection_result=result.get("detection_result"),
        decision=result.get("decision")
    )

@app.get("/api/chat")
async def chat_endpoint(question: str = Query(None), image_url: str = Query(None)):
    state: AgentState = {
        "question": question,
        "image_path": image_url,
        "image_description": None,
        "detection_result": None,
        "answer": None,
        "need_medication": None,
        "decision": None
    }
    result = graph_app.invoke(state)
    return result

@app.get("/api/chat/stream")
async def chat_stream_endpoint(question: str = Query(None), image_url: str = Query(None)):
    state: AgentState = {
        "question": question,
        "image_path": image_url,
        "image_description": None,
        "detection_result": None,
        "answer": None,
        "need_medication": None,
        "decision": None
    }
    
    def event_stream():
        for step in graph_app.stream(state, stream_mode="updates"):
            yield f"data: {step}\n\n"
    return StreamingResponse(event_stream(), media_type="text/event-stream")

def main():
    print("ğŸŒ½ æ™ºèƒ½ç³»ç»Ÿå¼€å§‹ï¼šæ”¯æŒå›¾åƒè·¯å¾„ + é—®é¢˜æ–‡å­—è¾“å…¥")
    print("ğŸ’¡ æç¤ºï¼šç³»ç»Ÿå°†æ¨¡æ‹ŸçœŸå®å¯¹è¯ï¼Œä¸€ä¸ªå­—ä¸€ä¸ªå­—åœ°è¾“å‡ºå›ç­”\n")
    
    # è¯¢é—®ç”¨æˆ·æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
    use_streaming = input("ğŸ¬ æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡ºæ•ˆæœï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower() == 'y'
    if use_streaming:
        print("âš ï¸  æ³¨æ„ï¼šæµå¼è¾“å‡ºå¯èƒ½åœ¨æŸäº›æƒ…å†µä¸‹å‡ºç°é‡å¤æ–‡æœ¬")
    print()

    # åˆå§‹åŒ–å¯¹è¯çŠ¶æ€ï¼Œä¿æŒä¸Šä¸‹æ–‡è¿ç»­æ€§
    conversation_state: AgentState = {
        "question": None,
        "image_path": None,
        "image_description": None,
        "detection_result": None,
        "answer": None,
        "need_medication": None,
        "decision": None
    }

    while True:
        img = input("ğŸ–¼ï¸ è¾“å…¥å›¾åƒè·¯å¾„ï¼ˆå¯ç•™ç©ºï¼‰ï¼š\n> ").strip()
        if img.lower() in ["", "æ— ", "æ— å›¾", "none", "no", "n"]:
            img = None

        txt = input("ğŸ“ è¾“å…¥é—®é¢˜ï¼ˆå¯ç•™ç©ºï¼‰ï¼š\n> ").strip()
        if not txt or txt.lower() in ["", "æ— ", "æ— å›¾", "none", "no", "n"]:
            txt = None
            if not img:
                print("è¯·è‡³å°‘æä¾›å›¾åƒæˆ–æ–‡æœ¬è¾“å…¥ã€‚")
                continue

        if txt and txt.lower() in ["é€€å‡º", "exit", "quit"]:
            print("å†è§ï¼æ„Ÿè°¢ä½¿ç”¨ç‰ç±³æ™ºèƒ½ç³»ç»Ÿï¼")
            break

        if not img and not txt:
            print("è¯·è‡³å°‘æä¾›å›¾åƒæˆ–æ–‡æœ¬è¾“å…¥ã€‚")
            continue

        # æ›´æ–°å¯¹è¯çŠ¶æ€ï¼Œä¿æŒä¸Šä¸‹æ–‡è¿ç»­æ€§
        if img:
            conversation_state["image_path"] = img
        if txt:
            conversation_state["question"] = txt
        
        print(f"\nğŸ§  æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜ï¼š{txt}")
        time.sleep(0.5)
        
        # è°ƒç”¨æ™ºèƒ½ä½“æ¨ç†
        result = graph_app.invoke(conversation_state)

        # æ›´æ–°å¯¹è¯çŠ¶æ€ï¼Œä¿å­˜æ¨ç†ç»“æœä¾›åç»­å¯¹è¯ä½¿ç”¨
        for key, value in result.items():
            if key in conversation_state:
                conversation_state[key] = value

        # æµå¼è¾“å‡ºç»“æœ
        if result.get("detection_result"):
            stream_agent_output("å›¾åƒè¯†åˆ«", result.get("detection_result"), use_streaming=use_streaming)
        
        if result.get("answer"):
            stream_agent_output("å†œä¸šä¸“å®¶", result.get("answer"), use_streaming=use_streaming)
        
        if result.get("decision"):
            stream_agent_output("å†œè¯ä¸“å®¶", result.get("decision"), use_streaming=use_streaming)

        # å¤šè½®å¯¹è¯å¾ªç¯
        while True:
            followup = input("\nğŸ‘´ğŸ» ç»§ç»­å¯¹è¯ï¼ˆè¾“å…¥æ–°é—®é¢˜ï¼Œæˆ–è¾“å…¥'é€€å‡º'ç»“æŸï¼‰ï¼š\n> ").strip()
            if followup and followup.lower() in ["é€€å‡º", "exit", "quit", "ç»“æŸ"]:
                break
            
            if followup:
                print(f"\nğŸ§  æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜ï¼š{followup}")
                time.sleep(0.5)
                
                # æ›´æ–°é—®é¢˜ï¼Œä½†ä¿æŒå…¶ä»–ä¸Šä¸‹æ–‡ä¿¡æ¯
                conversation_state["question"] = followup
                conversation_state["need_medication"] = None  # é‡ç½®å†³ç­–æ ‡å¿—
                
                # ç»§ç»­æ¨ç†ï¼Œä¼ å…¥å®Œæ•´çš„ä¸Šä¸‹æ–‡çŠ¶æ€
                result = graph_app.invoke(conversation_state)
                
                # æ›´æ–°å¯¹è¯çŠ¶æ€ï¼Œä¿å­˜æ¨ç†ç»“æœä¾›åç»­å¯¹è¯ä½¿ç”¨
                for key, value in result.items():
                    if key in conversation_state:
                        conversation_state[key] = value
                
                # æµå¼è¾“å‡ºç»“æœ
                if result.get("detection_result"):
                    stream_agent_output("å›¾åƒè¯†åˆ«", result.get("detection_result"), use_streaming=use_streaming)
                
                if result.get("answer"):
                    stream_agent_output("å†œä¸šä¸“å®¶", result.get("answer"), use_streaming=use_streaming)
                
                if result.get("decision"):
                    stream_agent_output("å†œè¯ä¸“å®¶", result.get("decision"), use_streaming=use_streaming)
            else:
                break

if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "api":
        print("ğŸš€ å¯åŠ¨FastAPIæœåŠ¡...")
        print("ğŸ“¡ APIæ¥å£ï¼š")
        print("   POST /api/ask - é—®ç­”æ¥å£")
        print("   GET  /api/chat - æ™®é€šé—®ç­”æ¥å£")
        print("   GET  /api/chat/stream - æµå¼é—®ç­”æ¥å£")
        print("ğŸŒ è®¿é—®åœ°å€ï¼šhttp://localhost:8000")
        uvicorn.run(app, host="0.0.0.0", port=8000)
    else:
        main()
