import os
from PIL import Image
import imagehash
from tqdm import tqdm
from collections import defaultdict
import sys
from itertools import combinations

# æ£€æŸ¥ä¾èµ–é¡¹
try:
    from PIL import Image
    import imagehash
except ImportError:
    print("æ­¤è„šæœ¬éœ€è¦ 'Pillow' å’Œ 'imagehash' åº“")
    print("è¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…: pip install Pillow imagehash")
    sys.exit(1)

def get_category_from_path(file_path):
    """ä»æ–‡ä»¶è·¯å¾„ä¸­æå–ç±»åˆ«ä¿¡æ¯"""
    path_parts = file_path.replace('\\', '/').split('/')
    if 'Healthy' in path_parts:
        return 'Healthy'
    elif 'Common_Rust' in path_parts:
        return 'Common_Rust'
    elif 'Blight' in path_parts:
        return 'Blight'
    elif 'Gray_Leaf_Spot' in path_parts:
        return 'Gray_Leaf_Spot'
    elif 'Blight_Rust' in path_parts:
        return 'Blight_Rust'
    elif 'Gray_Spot_Rust' in path_parts:
        return 'Gray_Spot_Rust'
    else:
        return 'Unknown'

def get_hash_variants(image, hash_size):
    """ä¸ºä¸€å¼ å›¾ç‰‡è®¡ç®—å…¶æ‰€æœ‰8ç§å¯¹ç§°å˜æ¢çš„å“ˆå¸Œå€¼"""
    hashes = set()
    # expand=True ç¡®ä¿æ—‹è½¬åçš„å›¾ç‰‡å°ºå¯¸æ­£ç¡®ï¼Œä¸ä¼šè¢«è£å‰ª
    rotations = [
        image,
        image.rotate(90, expand=True),
        image.rotate(180),
        image.rotate(270, expand=True)
    ]
    
    for img in rotations:
        # æ·»åŠ åŸå›¾å’Œæ°´å¹³ç¿»è½¬å›¾çš„å“ˆå¸Œ
        hashes.add(imagehash.phash(img, hash_size=hash_size))
        hashes.add(imagehash.phash(img.transpose(Image.FLIP_LEFT_RIGHT), hash_size=hash_size))
        
    return list(hashes)

def find_and_remove_deep_duplicates(root_folder, hash_size=8, threshold=5):
    """
    é€šè¿‡æ¨¡ç³ŠåŒ¹é…æ„ŸçŸ¥å“ˆå¸Œï¼ˆæ±‰æ˜è·ç¦»ï¼‰æ¥æŸ¥æ‰¾å¹¶åˆ é™¤è§†è§‰ä¸Šé«˜åº¦ç›¸ä¼¼çš„å›¾ç‰‡
    ï¼ˆåŒ…æ‹¬æ—‹è½¬ã€ç¿»è½¬ã€è½»å¾®å™ªç‚¹ã€å˜æ¢ç­‰ï¼‰ã€‚
    æ”¯æŒæ–°çš„æ•°æ®é›†ç›®å½•ç»“æ„ï¼ŒåŒ…æ‹¬å¤åˆç—…ä¾‹ã€‚
    """
    image_data = []
    files_to_scan = []
    category_stats = defaultdict(int)
    
    # å®šä¹‰é¢„æœŸçš„ç›®å½•ç»“æ„
    expected_dirs = [
        'Healthy',
        'Common_Rust',
        'Blight',
        'Gray_Leaf_Spot',
        'Compound_Cases/Blight_Rust',
        'Compound_Cases/Gray_Spot_Rust'
    ]
    
    print("ğŸ” æ£€æŸ¥æ•°æ®é›†ç›®å½•ç»“æ„...")
    for expected_dir in expected_dirs:
        dir_path = os.path.join(root_folder, expected_dir)
        if os.path.exists(dir_path):
            print(f"  âœ… æ‰¾åˆ°: {expected_dir}")
        else:
            print(f"  âš ï¸  ç¼ºå¤±: {expected_dir}")
    
    # 1. æ”¶é›†æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶çš„è·¯å¾„
    print("\nğŸ“‚ Step 1: æ‰«æå›¾ç‰‡æ–‡ä»¶...")
    valid_extensions = {".jpg", ".jpeg", ".png", ".bmp", ".webp"}
    for subdir, _, files in os.walk(root_folder):
        for file in files:
            if os.path.splitext(file)[1].lower() in valid_extensions:
                file_path = os.path.join(subdir, file)
                files_to_scan.append(file_path)
                category = get_category_from_path(file_path)
                category_stats[category] += 1
    
    if not files_to_scan:
        print("âŒ æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ã€‚")
        return

    # æ˜¾ç¤ºæ‰«æç»Ÿè®¡
    print(f"\nğŸ“Š æ‰«æç»Ÿè®¡:")
    print(f"  æ€»å›¾ç‰‡æ•°: {len(files_to_scan)}")
    for category, count in category_stats.items():
        print(f"  {category}: {count} å¼ ")
    
    # ç‰¹åˆ«æé†’é”ˆç—…æ ·æœ¬æ•°é‡
    rust_count = category_stats.get('Common_Rust', 0)
    if rust_count < 500:
        print(f"\nâš ï¸  æ³¨æ„: é”ˆç—…æ ·æœ¬æ•°é‡è¾ƒå°‘({rust_count}å¼ )ï¼Œå»ºè®®è¡¥å……æ›´å¤šæ ·æœ¬")
        print("   æ·±åº¦å»é‡å°†ç‰¹åˆ«ä¿æŠ¤é”ˆç—…æ ·æœ¬")

    # 2. ä¸ºæ¯å¼ å›¾ç‰‡è®¡ç®—å…¶æ‰€æœ‰å˜æ¢çš„å“ˆå¸Œå€¼
    print(f"\nğŸ” Step 2: è®¡ç®—å›¾ç‰‡æ‰€æœ‰å˜æ¢çš„å“ˆå¸Œå€¼ (hash_size={hash_size})...")
    for filepath in tqdm(files_to_scan, desc="è®¡ç®—å“ˆå¸Œ"):
        try:
            with Image.open(filepath) as img:
                # è½¬æ¢ä¸ºç°åº¦å›¾å¯ä»¥æé«˜å“ˆå¸Œçš„ç¨³å®šæ€§
                hash_variants = get_hash_variants(img.convert("L"), hash_size)
                category = get_category_from_path(filepath)
                image_data.append({'path': filepath, 'variants': hash_variants, 'category': category})
        except Exception as e:
            print(f"\nâŒ æ— æ³•å¤„ç†æ–‡ä»¶ {filepath}: {e}")

    # 3. ä½¿ç”¨æ±‰æ˜è·ç¦»æŸ¥æ‰¾ç›¸ä¼¼å›¾ç‰‡ç»„
    print(f"\nğŸ” Step 3: æŸ¥æ‰¾ç›¸ä¼¼å›¾ç‰‡ (æ±‰æ˜è·ç¦» <= {threshold})...")
    
    duplicates_to_remove = set()
    category_duplicates = defaultdict(int)
    rust_protected = 0
    
    # O(n^2 * k) çš„æ¯”è¾ƒï¼Œå…¶ä¸­ k æ˜¯å“ˆå¸Œå˜ä½“çš„æ•°é‡
    for i in tqdm(range(len(image_data)), desc="æ¯”è¾ƒå›¾ç‰‡"):
        path_i = image_data[i]['path']
        category_i = image_data[i]['category']
        
        if path_i in duplicates_to_remove:
            continue
            
        variants_i = image_data[i]['variants']
        # åªå– j çš„ä¸»å“ˆå¸Œè¿›è¡Œæ¯”è¾ƒï¼Œå¯ä»¥æå¤§åœ°åŠ é€Ÿï¼Œä¸”ç»“æœåŸºæœ¬ä¸€è‡´
        primary_hash_i = variants_i[0]
        
        for j in range(i + 1, len(image_data)):
            path_j = image_data[j]['path']
            category_j = image_data[j]['category']
            
            if path_j in duplicates_to_remove:
                continue
            
            variants_j = image_data[j]['variants']
            
            # æ£€æŸ¥ i çš„ä¸»å“ˆå¸Œæ˜¯å¦ä¸ j çš„ä»»ä½•å˜ä½“ç›¸ä¼¼
            for hash_j in variants_j:
                if (primary_hash_i - hash_j) <= threshold:
                    # æ‰¾åˆ°äº†ç›¸ä¼¼é¡¹ï¼Œå†³å®šåˆ é™¤å“ªä¸ª
                    
                    # ç‰¹æ®Šä¿æŠ¤é”ˆç—…æ ·æœ¬
                    if rust_count < 500:
                        if category_i == 'Common_Rust' and category_j != 'Common_Rust':
                            # ä¿ç•™é”ˆç—…æ ·æœ¬iï¼Œåˆ é™¤j
                            duplicates_to_remove.add(path_j)
                            category_duplicates[category_j] += 1
                            rust_protected += 1
                            break
                        elif category_j == 'Common_Rust' and category_i != 'Common_Rust':
                            # ä¿ç•™é”ˆç—…æ ·æœ¬jï¼Œåˆ é™¤i
                            duplicates_to_remove.add(path_i)
                            category_duplicates[category_i] += 1
                            rust_protected += 1
                            break
                        elif category_i == 'Common_Rust' and category_j == 'Common_Rust':
                            # ä¸¤ä¸ªéƒ½æ˜¯é”ˆç—…æ ·æœ¬ï¼Œåªåˆ é™¤jï¼ˆä¿ç•™è¾ƒæ—©çš„ï¼‰
                            duplicates_to_remove.add(path_j)
                            category_duplicates[category_j] += 1
                            break
                    
                    # å¸¸è§„å¤„ç†ï¼šå°† j æ ‡è®°ä¸ºå¾…åˆ é™¤ï¼Œç„¶ååœæ­¢æ¯”è¾ƒ j
                    duplicates_to_remove.add(path_j)
                    category_duplicates[category_j] += 1
                    break
    
    # 4. åˆ é™¤è¢«æ ‡è®°ä¸ºé‡å¤çš„æ–‡ä»¶
    print(f"\nğŸ—‘ï¸  Step 4: å‘ç° {len(duplicates_to_remove)} å¼ é«˜åº¦ç›¸ä¼¼å›¾ç‰‡ (åŒ…æ‹¬å˜æ¢) å¾…åˆ é™¤...")
    if not duplicates_to_remove:
        print("âœ… æœªå‘ç°é«˜åº¦ç›¸ä¼¼çš„é‡å¤é¡¹ã€‚æ‚¨çš„æ•°æ®é›†éå¸¸å¹²å‡€!")
        return
    
    print(f"\nğŸ“Š å„ç±»åˆ«é‡å¤æ–‡ä»¶ç»Ÿè®¡:")
    for category, count in category_duplicates.items():
        print(f"  {category}: {count} å¼ é«˜åº¦ç›¸ä¼¼æ–‡ä»¶")
    
    if rust_protected > 0:
        print(f"\nğŸ”¥ é”ˆç—…æ ·æœ¬ä¿æŠ¤: åœ¨ {rust_protected} ä¸ªç›¸ä¼¼ç»„ä¸­ä¼˜å…ˆä¿ç•™äº†é”ˆç—…æ ·æœ¬")
        
    for duplicate_path in tqdm(list(duplicates_to_remove), desc="åˆ é™¤æ–‡ä»¶"):
        try:
            os.remove(duplicate_path)
        except OSError as e:
            print(f"    âŒ åˆ é™¤å¤±è´¥: {duplicate_path}: {e}")

    # 5. æœ€ç»ˆç»Ÿè®¡
    print(f"\n" + "="*60)
    print(f"ğŸ‰ æ·±åº¦å»é‡æ‰«æå®Œæˆ")
    print(f"æ€»å¤„ç†å›¾ç‰‡: {len(files_to_scan)}")
    print(f"å”¯ä¸€å›¾ç‰‡ (æ·±åº¦æ¸…ç†å): {len(files_to_scan) - len(duplicates_to_remove)}")
    print(f"é«˜åº¦ç›¸ä¼¼å›¾ç‰‡åˆ é™¤: {len(duplicates_to_remove)}")
    
    if rust_protected > 0:
        print(f"ğŸ”¥ é”ˆç—…æ ·æœ¬ä¿æŠ¤: {rust_protected} ç»„")
    
    print(f"\nğŸ“Š å„ç±»åˆ«åˆ é™¤ç»Ÿè®¡:")
    for category, count in category_duplicates.items():
        print(f"  {category}: åˆ é™¤äº† {count} å¼ é«˜åº¦ç›¸ä¼¼å›¾ç‰‡")
    
    # æœ€ç»ˆå„ç±»åˆ«å‰©ä½™æ•°é‡
    print(f"\nğŸ“ˆ æ¸…ç†åå„ç±»åˆ«å‰©ä½™æ•°é‡:")
    final_stats = defaultdict(int)
    
    # é‡æ–°æ‰«æå‰©ä½™æ–‡ä»¶
    for subdir, _, files in os.walk(root_folder):
        for file in files:
            if os.path.splitext(file)[1].lower() in valid_extensions:
                file_path = os.path.join(subdir, file)
                category = get_category_from_path(file_path)
                final_stats[category] += 1
    
    for category, count in final_stats.items():
        print(f"  {category}: {count} å¼ ")
    
    print("="*60)

if __name__ == "__main__":
    dataset_directory = 'datasets'
    
    if not os.path.isdir(dataset_directory):
        print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ° '{dataset_directory}' ç›®å½•")
        print("è¯·ç¡®ä¿æ­¤è„šæœ¬ä¸ 'datasets' æ–‡ä»¶å¤¹åœ¨åŒä¸€ç›®å½•ä¸­")
    else:
        print("ğŸ¯ --- æ·±åº¦è§†è§‰å»é‡è„šæœ¬ ---")
        print("æ­¤è„šæœ¬è¯†åˆ«å¹¶åˆ é™¤é«˜åº¦ç›¸ä¼¼çš„å›¾ç‰‡ï¼Œ")
        print("åŒ…æ‹¬æ—‹è½¬ (90/180/270åº¦)ã€ç¿»è½¬æˆ–æœ‰è½»å¾®å™ªç‚¹çš„å›¾ç‰‡")
        print("å®ƒé€šè¿‡æ¯”è¾ƒæ‰€æœ‰å¯¹ç§°å˜æ¢æ¥å·¥ä½œ")
        print("\næ”¯æŒçš„æ•°æ®é›†ç»“æ„:")
        print("  - Healthy/")
        print("  - Common_Rust/")
        print("  - Blight/")
        print("  - Gray_Leaf_Spot/")
        print("  - Compound_Cases/Blight_Rust/")
        print("  - Compound_Cases/Gray_Spot_Rust/")
        print("\nğŸš¨ è­¦å‘Š: è¿™æ˜¯æœ€ç»ˆå’Œæœ€æ¿€è¿›çš„æ¸…ç†æ­¥éª¤ã€‚å°†æ°¸ä¹…åˆ é™¤æ–‡ä»¶")
        print("ğŸ”¥ ç‰¹åˆ«æ³¨æ„: ä¼šç‰¹åˆ«ä¿æŠ¤é”ˆç—…æ ·æœ¬")
        
        user_confirmation = input("\nç¡®å®šè¦ç»§ç»­å—? (yes/no): ")
        
        if user_confirmation.lower() == 'yes':
            print("\nğŸš€ å¼€å§‹æ·±åº¦è§†è§‰å»é‡å¤„ç†...")
            # ä½¿ç”¨ä¸€ä¸ªç›¸å¯¹ä¿å®ˆä½†æœ‰æ•ˆçš„é˜ˆå€¼
            find_and_remove_deep_duplicates(dataset_directory, hash_size=8, threshold=5)
        else:
            print("\nâŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ") 